{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw0lMdn_5oCB"
      },
      "source": [
        "# **Taller de aplicaciones de python y numpy en AI**\n",
        "\n",
        "Completa los espacios en blanco para que el script se ejecute correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKsH5Gl-7OdD"
      },
      "source": [
        "## Módulo 1: Preprocesamiento de texto – Tokenización y representación eficiente\n",
        "Contexto práctico:\n",
        "En tareas de clasificación de texto, como analizar sentimientos en reseñas o construir asistentes conversacionales, el primer paso crucial es convertir texto en números. Aunque hoy usamos librerías como spaCy o scikit-learn, entender cómo funciona internamente el tokenizador y los vectores de palabras te permite:\n",
        "\n",
        "Optimizar pipelines.\n",
        "\n",
        "Depurar errores.\n",
        "\n",
        "Implementar soluciones personalizadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-fKmHfN7RAU"
      },
      "source": [
        "### Actividad:\n",
        "Simularemos un tokenizador básico y construiremos una representación por frecuencia (tipo Bag-of-Words)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZimwQTq6jNi"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# MÓDULO 1: Clasificación de texto – Tokenización y representación eficiente\n",
        "# ========================================\n",
        "\n",
        "\"\"\"\n",
        "Contexto:\n",
        "Convertir texto en vectores es el primer paso en tareas como clasificación o análisis de sentimientos.\n",
        "Aquí implementaremos un tokenizador y representaciones tipo Bag-of-Words.\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.lower().split()\n",
        "\n",
        "def build_vocab(texts):\n",
        "    vocab = set()\n",
        "    for t in texts:\n",
        "        tokens = tokenize(t)\n",
        "        ______.update(tokens)\n",
        "    return vocab\n",
        "\n",
        "def count_words(texts):\n",
        "    word_count = {}\n",
        "    for t in texts:\n",
        "        tokens = tokenize(t)\n",
        "        for token in tokens:\n",
        "            word_count[_____] = word_count.get(_____, 0) + 1\n",
        "    return word_count\n",
        "\n",
        "texts = [\n",
        "    \"Modelo de aprendizaje automático para clasificación de texto\",\n",
        "    \"Datos, datos y más datos\",\n",
        "    \"La inteligencia artificial aprende con algoritmos\"\n",
        "]\n",
        "\n",
        "print(\"Vocabulario:\", build_vocab(texts))\n",
        "print(\"Frecuencias:\", count_words(texts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNy_lgV47s3Q"
      },
      "source": [
        "## Módulo 2: Sistema de recomendación – Similitud entre usuarios\n",
        "Contexto práctico:\n",
        "\n",
        "Los sistemas de recomendación (Netflix, Amazon, Spotify) comparan perfiles de usuarios para sugerir contenido. Uno de los métodos más comunes es medir similitud entre vectores de preferencias usando similitud de coseno.\n",
        "\n",
        "Aprendizaje clave:\n",
        "Cómo representar usuarios con vectores.\n",
        "\n",
        "Cómo calcular similitud eficiente entre ellos.\n",
        "\n",
        "Usar NumPy para trabajar con datos tabulares y operar sobre matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVNcckM_7_QM"
      },
      "source": [
        "### Actividad:\n",
        "Simularemos una matriz de calificaciones y encontraremos los usuarios más similares a uno dado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKl3rb_T7slv"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# MÓDULO 2: Sistema de recomendación – Similitud entre usuarios\n",
        "# ========================================\n",
        "\n",
        "\"\"\"\n",
        "Contexto:\n",
        "Usamos vectores de calificaciones para calcular la similitud entre usuarios.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "ratings = np.array([\n",
        "    [5, 3, 0, 1],\n",
        "    [4, 0, 0, 1],\n",
        "    [1, 1, 0, 5],\n",
        "    [1, 0, 0, 4],\n",
        "    [0, 1, 5, 4]\n",
        "])\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    if norm(a) == 0 or norm(b) == 0:\n",
        "        return 0\n",
        "    return np.dot(a, b) / (______ * norm(b))\n",
        "\n",
        "def find_most_similar(user_index, ratings):\n",
        "    similarities = []\n",
        "    for i in range(ratings.shape[0]):\n",
        "        if i != user_index:\n",
        "            sim = cosine_similarity(ratings[user_index], ratings[i])\n",
        "            similarities.append((_____, ______))\n",
        "    return sorted(similarities, key=lambda x: -x[1])\n",
        "\n",
        "print(\"Usuarios similares al usuario 0:\", find_most_similar(0, ratings)) b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK4UqT5WziCN"
      },
      "source": [
        "## Módulo 3: Optimización adaptativa - Búsqueda de hiperparámetros\n",
        "Contexto práctico:\n",
        "Entrenar un modelo implica ajustar parámetros como la tasa de aprendizaje o la profundidad del árbol. Evaluar cada combinación puede tomar minutos u horas. Por eso, es fundamental reutilizar resultados anteriores (memorization) y aplicar heurísticas.\n",
        "\n",
        "Aprendizaje clave:\n",
        "Estructuras como diccionarios para cache.\n",
        "\n",
        "Búsqueda sistemática vs heurística.\n",
        "\n",
        "Principios de eficiencia computacional.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEY9bLrp6G_N"
      },
      "source": [
        "### Actividad:\n",
        "Simularemos la búsqueda de hiperparámetros con una función de evaluación costosa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cI7za7bZzhs8"
      },
      "outputs": [],
      "source": [
        "# =============================================================\n",
        "# MÓDULO 3: Optimización adaptativa – Búsqueda de hiperparámetros\n",
        "# ==============================================================\n",
        "\n",
        "import random\n",
        "\n",
        "def evaluate_model(alpha, beta):\n",
        "    return -((alpha - 3)**2 + (beta - 2)**2) + 10\n",
        "\n",
        "cache = {}\n",
        "\n",
        "def memoized_eval(alpha, beta):\n",
        "    key = (alpha, beta)\n",
        "    if key in cache:\n",
        "        return cache[key]\n",
        "    result = evaluate_model(alpha, beta)\n",
        "    cache[key] = result\n",
        "    return result\n",
        "\n",
        "def grid_search():\n",
        "    best_score = -float(\"inf\")\n",
        "    best_params = None\n",
        "    for a in range(0, 7):\n",
        "        for b in range(0, 7):\n",
        "            score = memoized_eval(____, _____)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_params = (_____, ______)\n",
        "    return best_params, best_score\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_search())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkiNYP_70vSp"
      },
      "source": [
        "## Procesamiento de imágenes – Convolución 2D\n",
        "Contexto práctico:\n",
        "\n",
        "Las redes convolucionales (CNNs) aplican filtros (kernels) para detectar bordes, texturas, formas, etc. Antes de entrenar una red, necesitas entender cómo se aplica una convolución a una imagen.\n",
        "\n",
        "Aprendizaje clave:\n",
        "Representar imágenes como arrays NumPy.\n",
        "\n",
        "Usar slicing para aplicar filtros 2D.\n",
        "\n",
        "Simular una operación fundamental en visión por computador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW2aLT_k6K6I"
      },
      "source": [
        "### Actividad:\n",
        "Aplicaremos un filtro de detección de bordes a una imagen simulada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3G0DN6x0u_m"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# MÓDULO 4: Procesamiento de imágenes – Convolución 2D\n",
        "# ========================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = np.zeros((100, 100))\n",
        "img[30:70, 30:70] = 255\n",
        "img += np.random.normal(0, 10, img.shape)\n",
        "img = np.clip(img, 0, 255)\n",
        "\n",
        "kernel = np.array([[-1, -1, -1],\n",
        "                   [-1,  8, -1],\n",
        "                   [-1, -1, -1]])\n",
        "\n",
        "def convolve2d(img, kernel):\n",
        "    h, w = img.shape\n",
        "    kh, kw = kernel.shape\n",
        "    result = np.zeros((h - kh + 1, w - kw + 1))\n",
        "    for i in range(result.shape[0]):\n",
        "        for j in range(result.shape[1]):\n",
        "            region = img[i:i+kh, j:j+kw]\n",
        "            result[i, j] = np.sum(______ * ______)\n",
        "    return result\n",
        "\n",
        "result = convolve2d(img, kernel)\n",
        "plt.imshow(result, cmap='gray')\n",
        "plt.title(\"Resultado de la convolución\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPkaUTMy2IdZ"
      },
      "source": [
        "## El Problema del Viajero (TSP)\n",
        "Es clásico en logística: ¿cuál es la ruta más corta para visitar N lugares y volver al origen? Se usa en ruteo de vehículos, planificación de entregas, etc.\n",
        "\n",
        "Aprendizaje clave:\n",
        "Representar problemas como grafos o matrices.\n",
        "\n",
        "Implementar soluciones heurísticas (fuerza bruta, greedy).\n",
        "\n",
        "Calcular distancias entre puntos con NumPy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6UOaUJz2INK"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# MÓDULO 5: Problema del viajero (TSP) – Heurística greedy\n",
        "# ========================================\n",
        "\n",
        "np.random.seed(42)\n",
        "ciudades = np.random.rand(6, 2) * 100\n",
        "\n",
        "def distancia(ciudades):\n",
        "    n = len(ciudades)\n",
        "    D = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            D[i, j] = np.______.norm(ciudades[i] - ciudades[j])\n",
        "    return D\n",
        "\n",
        "def tsp_greedy(dist_matrix):\n",
        "    n = len(dist_matrix)\n",
        "    visitado = set()\n",
        "    ruta = [0]\n",
        "    visitado.add(0)\n",
        "    while len(ruta) < n:\n",
        "        last = ruta[-1]\n",
        "        min_dist = float('inf')\n",
        "        next_city = None\n",
        "        for j in range(n):\n",
        "            if j not in visitado and dist_matrix[last][j] < min_dist:\n",
        "                min_dist = dist_matrix[last][j]\n",
        "                next_city = j\n",
        "        ruta.append(________)\n",
        "        visitado.add(________)\n",
        "    ruta.append(0)\n",
        "    return ruta\n",
        "\n",
        "def plot_ruta(ruta, coords):\n",
        "    x = [coords[i][0] for i in ruta]\n",
        "    y = [coords[i][1] for i in ruta]\n",
        "    plt.plot(x, y, marker='o')\n",
        "    for i, (xx, yy) in enumerate(coords):\n",
        "        plt.text(xx + 1, yy + 1, str(i))\n",
        "    plt.title(\"Ruta aproximada (heurística greedy)\")\n",
        "    plt.show()\n",
        "\n",
        "D = distancia(ciudades)\n",
        "ruta = tsp_greedy(D)\n",
        "plot_ruta(ruta, ciudades)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
